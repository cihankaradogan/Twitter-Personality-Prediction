{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "prediction_gui.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cihankaradogan/Twitter-Personality-Prediction/blob/main/prediction_gui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krLnPalkukiL"
      },
      "source": [
        "# Environment setup & function definitions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNBksnaYuoPJ"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_TUjPK7up0G",
        "outputId": "f6545e4d-f5a7-4656-e25b-02822456bc35"
      },
      "source": [
        "!pip install transformers==3.5.1\n",
        "!pip install turkish-twitter-preprocess==0.0.7\n",
        "!pip install nltk\n",
        "!pip install snscrape\n",
        "!pip install emoji\n",
        "!pip install torch==1.7.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3.5.1 in /usr/local/lib/python3.7/dist-packages (3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.3.2)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (0.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.17.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (0.1.91)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.1) (2.4.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: turkish-twitter-preprocess==0.0.7 in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.2.6)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMUmJmI3uqpd"
      },
      "source": [
        "import torch\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA_wfkcLuysG",
        "outputId": "9b6f715a-aaed-4553-ed53-1d064d209daa"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9IjU88i2v5I",
        "outputId": "9e809aaf-3ab2-4de2-d267-b7d9e1d6d1a6"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTdQt_v2wqnV"
      },
      "source": [
        "## Loading models\n",
        "### we have 10 different models for now\n",
        "#### 5 criteria, 5 personality traits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsWi_Z3Swsnk",
        "cellView": "form"
      },
      "source": [
        "# MUHIKT => Muhalefet Iktidar\n",
        "# DUYGUDURUM => Duygusal Yonelim(Hayattan memnuniyet, karamsarlik)\n",
        "# GELIR => Gelir seviyesi, 4 ayri kategoride degerlendirme\n",
        "# ALKOL => Alkole bakış açısı\n",
        "# DIN => Dine bakış açısı\n",
        "PATH_MUHIKT = '/content/drive/MyDrive/modeller/iktidar_muhalefet.pt' #@param {type:\"string\"}\n",
        "muhikt_model = torch.load(PATH_MUHIKT)\n",
        "\n",
        "PATH_DUYGUDURUM = '/content/drive/MyDrive/modeller/duygudurum.pt' #@param {type:\"string\"}\n",
        "duygudurum_model = torch.load(PATH_DUYGUDURUM)\n",
        "\n",
        "PATH_GELIR = '/content/drive/MyDrive/modeller/gelir.pt' #@param {type:\"string\"}\n",
        "gelir_model = torch.load(PATH_GELIR)\n",
        "\n",
        "PATH_ALKOL = '/content/drive/MyDrive/modeller/alkol.pt' #@param {type:\"string\"}\n",
        "alkol_model = torch.load(PATH_ALKOL)\n",
        "\n",
        "PATH_DIN = '/content/drive/MyDrive/modeller/din.pt' #@param {type:\"string\"}\n",
        "din_model = torch.load(PATH_DIN)\n",
        "\n",
        "# AGREE, CONS, OPEN, NEVRO, EXTRA\n",
        "PATH_AGREE = '/content/drive/MyDrive/modeller/Agreeableness_28k_9epoch.pt' #@param {type:\"string\"}\n",
        "agree_model = torch.load(PATH_AGREE)\n",
        "\n",
        "PATH_CONS = '/content/drive/MyDrive/modeller/conscientiousness.pt' #@param {type:\"string\"}\n",
        "cons_model = torch.load(PATH_CONS)\n",
        "\n",
        "PATH_OPEN = '/content/drive/MyDrive/modeller/Openness_28k.pt' #@param {type:\"string\"}\n",
        "open_model = torch.load(PATH_OPEN)\n",
        "\n",
        "PATH_NEVRO = '/content/drive/MyDrive/modeller/nevro.pt' #@param {type:\"string\"}\n",
        "nevro_model = torch.load(PATH_NEVRO)\n",
        "\n",
        "PATH_EXTRA = '/content/drive/MyDrive/modeller/extraversion.pt' #@param {type:\"string\"}\n",
        "extra_model = torch.load(PATH_EXTRA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ROc5gfy5ti"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCNpKVWPy6Uc"
      },
      "source": [
        "import sys\n",
        "import ttp\n",
        "import nltk\n",
        "import json\n",
        "import itertools\n",
        "import snscrape.modules.twitter as sntwitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2IWHs0Zy-m4"
      },
      "source": [
        "def save_tweets_with_query(query, n_tweets, stopwords, filename, save_to_file):\n",
        "    data = list()\n",
        "    index = 1\n",
        "    output_stream = sys.stdout\n",
        "    tweets_gen = sntwitter.TwitterSearchScraper(query).get_items()\n",
        "    top_tweets = itertools.islice(tweets_gen, n_tweets)\n",
        "    for tweet in top_tweets:\n",
        "        # writer.writerow([tweet.id, tweet.date, tweet.username, tweet.content, tweet.url])\n",
        "        pped_sentence = ttp.preprocess_sentence(tweet.content, stopwords)\n",
        "        data.append({\"sentence\": pped_sentence, \"date\": str(tweet.date)})\n",
        "        output_stream.write('Scraped tweets: %s\\r' % index)\n",
        "        output_stream.flush()\n",
        "        index += 1\n",
        "    if save_to_file:\n",
        "      with open(filename, 'w', encoding='utf-8') as outfile:\n",
        "        json.dump(data, outfile, ensure_ascii=False)\n",
        "    print('')\n",
        "    print('Done!')\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoZMh94kzAh5"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "\n",
        "def print_tabulate(table_values):\n",
        "  table_names = ['name', 'perc(%)', 'count']\n",
        "  print(tabulate(table_values, headers=table_names))\n",
        "\n",
        "def print_percentage(df, first_criteria, second_criteria, first_criteria_val, column_name):\n",
        "  total_count = 0\n",
        "  first_count = 0\n",
        "  second_count = 0\n",
        "  for idx, row in tqdm(df.iterrows()):\n",
        "    if row[column_name] == first_criteria_val:\n",
        "      first_count += 1\n",
        "    else:\n",
        "      second_count += 1\n",
        "    total_count += 1\n",
        "  print()\n",
        "  result_first = str(first_count / (total_count / 100))\n",
        "  result_second = str(second_count / (total_count / 100))\n",
        "  slice_idx_first, slice_idx_second = 4, 4\n",
        "  if len(result_first) < 4:\n",
        "    slice_idx_first = 2\n",
        "  if len(result_second) < 4:\n",
        "    slice_idx_second = 2\n",
        "  table_values = [\n",
        "                  [first_criteria, f\"{result_first[:slice_idx_first]}%\", first_count],\n",
        "                  [second_criteria, f\"{result_second[:slice_idx_second]}%\", second_count],\n",
        "                  ['total', '100%', total_count],\n",
        "                ]\n",
        "  print_tabulate(table_values)\n",
        "\n",
        "def return_percentage_bigfive(df, first_criteria, first_criteria_val, column_name):\n",
        "  total_count = 0\n",
        "  first_count = 0\n",
        "  second_count = 0\n",
        "  for idx, row in tqdm(df.iterrows()):\n",
        "    if row[column_name] == first_criteria_val:\n",
        "      first_count += 1\n",
        "    else:\n",
        "      second_count += 1\n",
        "    total_count += 1\n",
        "  print()\n",
        "  result_first = str(first_count / (total_count / 100))\n",
        "  slice_idx_first, slice_idx_second = 4, 4\n",
        "  if len(result_first) < 4:\n",
        "    slice_idx_first = 2\n",
        "  return [first_criteria, f\"{result_first[:slice_idx_first]}%\", first_count]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEJIjvxPzBuU"
      },
      "source": [
        "from operator import itemgetter\n",
        "def add_count_to_map(map, col_name):\n",
        "  if col_name in map.keys():\n",
        "    map[col_name] += 1\n",
        "  else:\n",
        "    map[col_name] = 1\n",
        "  map['total'] += 1\n",
        "  return map\n",
        "\n",
        "def calc_perc(map, key):\n",
        "  total_count = map['total']\n",
        "  result = map[key] / (total_count / 100) \n",
        "  return  \"%\" + str(result)[:4]\n",
        "\n",
        "def print_percentage_multi(df, map, column_name):\n",
        "  count_map = {'total': 0}\n",
        "  for idx, row in tqdm(df.iterrows()):\n",
        "    add_count_to_map(count_map, map[row[column_name]])\n",
        "  print()\n",
        "  \n",
        "  table_names = ['name', 'perc(%)', 'count']\n",
        "  table_values = list()\n",
        "  for key in count_map:\n",
        "    table_values.append([key, calc_perc(count_map, key), count_map[key]])\n",
        "\n",
        "  table_values.sort(key=itemgetter(2))\n",
        "  print(tabulate(table_values, headers=table_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC1sw9HazDwU"
      },
      "source": [
        "def predict(model, prediction_dataloader):\n",
        "  print('Prediction started on test data')\n",
        "  model.eval()\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    # label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    # true_labels.append(label_ids)\n",
        "  print('Prediction completed')\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK38mLDBzHyv"
      },
      "source": [
        "def map_predictions_to_df(df, predictions, column_str):\n",
        "  prediction_set = []\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    prediction_set.append(pred_labels_i)\n",
        "\n",
        "  prediction_scores = [item for sublist in prediction_set for item in sublist]\n",
        "  df[column_str] = prediction_scores\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RVWtunDzJA4"
      },
      "source": [
        "def predict_query(query, n_tweets):\n",
        "  print('Started fetching...')\n",
        "  data = save_tweets_with_query(query, n_tweets, stop_word_list, \"na\", False)\n",
        "  local_df = pd.DataFrame(data).drop_duplicates(['sentence'])\n",
        "  print('Started formatting...')\n",
        "\n",
        "  test_texts = local_df.sentence.values\n",
        "  input_ids = list()\n",
        "  attention_masks = list()\n",
        "  max_len = 250\n",
        "\n",
        "  for text in test_texts:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          text,                     \n",
        "                          add_special_tokens = True, \n",
        "                          max_length = max_len,          \n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,  \n",
        "                          return_tensors = 'pt',\n",
        "                          truncation=True\n",
        "                    )\n",
        "      \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  batch_size = 32  \n",
        "\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "  print('Started predicting...')\n",
        "  muhikt_predictions = predict(muhikt_model, prediction_dataloader)\n",
        "  duygu_predictions = predict(duygudurum_model, prediction_dataloader)\n",
        "  gelir_predictions = predict(gelir_model, prediction_dataloader)\n",
        "  alkol_predictions = predict(alkol_model, prediction_dataloader)\n",
        "  din_predictions = predict(din_model, prediction_dataloader)\n",
        "\n",
        "  agree_predictions = predict(agree_model, prediction_dataloader)\n",
        "  cons_predictions = predict(cons_model, prediction_dataloader)\n",
        "  extra_predictions = predict(extra_model, prediction_dataloader)\n",
        "  nevro_predictions = predict(nevro_model, prediction_dataloader)\n",
        "  open_predictions = predict(open_model, prediction_dataloader)\n",
        "\n",
        "  map_predictions_to_df(local_df, muhikt_predictions, 'muhikt')\n",
        "  map_predictions_to_df(local_df, gelir_predictions, 'gelir')\n",
        "  map_predictions_to_df(local_df, duygu_predictions, 'duygu')\n",
        "  map_predictions_to_df(local_df, alkol_predictions, 'alkol')\n",
        "  map_predictions_to_df(local_df, din_predictions, 'din')\n",
        "  \n",
        "  map_predictions_to_df(local_df, agree_predictions, 'agree')\n",
        "  map_predictions_to_df(local_df, cons_predictions, 'cons')\n",
        "  map_predictions_to_df(local_df, extra_predictions, 'extra')\n",
        "  map_predictions_to_df(local_df, nevro_predictions, 'nevro')\n",
        "  map_predictions_to_df(local_df, open_predictions, 'open')\n",
        "  \n",
        "  print('Finished and printing results...')\n",
        "  print_percentage(local_df, 'muhalefet', 'iktidar', 1, 'muhikt')\n",
        "  print_percentage(local_df, 'karamsar', 'memnun', 0, 'duygu')\n",
        "  print_percentage(local_df, 'alkol-olumlu', 'alkol-olumsuz', 0, 'alkol')\n",
        "  print_percentage(local_df, 'din-olumlu', 'din-olumsuz', 0, 'din')\n",
        "  print_percentage_multi(\n",
        "    local_df,\n",
        "    {0: 'işçi', 1: 'memur', 2: 'tüccar', 3: 'öğrenci'},\n",
        "    'gelir'\n",
        "    )\n",
        "  \n",
        "  bigfive_result_list = list()\n",
        "  for domain in ['agree', 'cons', 'extra', 'nevro', 'open']:\n",
        "    bigfive_result_list.append(return_percentage_bigfive(local_df, domain, 1, domain))\n",
        "  print_tabulate(bigfive_result_list)\n",
        "\n",
        "  print(f\"{query} - {len(local_df)}\")\n",
        "  return local_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwLnjO9Y0oIc"
      },
      "source": [
        "## Loading finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM4KlsiQ0ol6",
        "outputId": "1a4d4bea-7d13-4b46-fbd1-e1f7027314f8"
      },
      "source": [
        "finetuned = 'dbmdz/bert-base-turkish-128k-uncased' #@param {type:\"string\"}\n",
        "tokenizer = BertTokenizer.from_pretrained(finetuned, do_lower_case=True)\n",
        "nltk.download('stopwords')\n",
        "stop_word_list = nltk.corpus.stopwords.words('turkish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPKT58BO1oVX"
      },
      "source": [
        "# Prototype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gX98IYi1ssP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ff8296d3-699f-4887-be85-d2f5861532ee"
      },
      "source": [
        "username = 'Twitter Username' #@param {type:\"string\"}\n",
        "result = predict_query(f\"(from:{username}) lang:tr -filter:replies\", 2500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started fetching...\n",
            "\n",
            "Done!\n",
            "Started formatting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started predicting...\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Prediction started on test data\n",
            "Prediction completed\n",
            "Finished and printing results...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8765.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "name       perc(%)      count\n",
            "---------  ---------  -------\n",
            "muhalefet  74.6%         1838\n",
            "iktidar    25.3%          624\n",
            "total      100%          2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 7904.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "name      perc(%)      count\n",
            "--------  ---------  -------\n",
            "karamsar  27.7%          683\n",
            "memnun    72.2%         1779\n",
            "total     100%          2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8409.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "name           perc(%)      count\n",
            "-------------  ---------  -------\n",
            "alkol-olumlu   40.8%         1005\n",
            "alkol-olumsuz  59.1%         1457\n",
            "total          100%          2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8196.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "name         perc(%)      count\n",
            "-----------  ---------  -------\n",
            "din-olumlu   26.4%          652\n",
            "din-olumsuz  73.5%         1810\n",
            "total        100%          2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 7936.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "name     perc(%)      count\n",
            "-------  ---------  -------\n",
            "öğrenci  %15.6          385\n",
            "tüccar   %22.0          543\n",
            "işçi     %30.1          742\n",
            "memur    %32.1          792\n",
            "total    %100.         2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8493.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8862.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8703.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 9053.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2462it [00:00, 8470.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "name    perc(%)      count\n",
            "------  ---------  -------\n",
            "agree   39.6%          975\n",
            "cons    83.1%         2046\n",
            "extra   88.2%         2173\n",
            "nevro   11.9%          294\n",
            "open    37.2%          918\n",
            "(from:Twitter Username) lang:tr -filter:replies - 2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "r2X34RH_mO5K",
        "outputId": "089acdc3-e9d7-4a35-d03f-f3c8e57421ba"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>date</th>\n",
              "      <th>muhikt</th>\n",
              "      <th>gelir</th>\n",
              "      <th>duygu</th>\n",
              "      <th>alkol</th>\n",
              "      <th>din</th>\n",
              "      <th>agree</th>\n",
              "      <th>cons</th>\n",
              "      <th>extra</th>\n",
              "      <th>nevro</th>\n",
              "      <th>open</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pazar günü bulgaristan’da gerçekleşecek olan s...</td>\n",
              "      <td>2021-11-12 12:03:48+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gönlümüzde biriken tüm umutlarımızı yeşert ala...</td>\n",
              "      <td>2021-11-12 07:31:15+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ankara büyükşehir belediye başkanımız kıymetli...</td>\n",
              "      <td>2021-11-10 08:56:21+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>türk miletinin fikrine kalbine ve ruhuna işlen...</td>\n",
              "      <td>2021-11-09 17:34:31+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tbm grubu toplantımızdayız</td>\n",
              "      <td>2021-11-09 06:47:03+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>sadece fransızların değil tüm insanlığın ortak...</td>\n",
              "      <td>2019-04-16 06:20:30+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>türk milî takımı formasını hem basketbol hem d...</td>\n",
              "      <td>2019-04-12 16:33:28+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>mesele tarih ise kanuni nin fransuva ya yazdığ...</td>\n",
              "      <td>2019-04-12 16:11:20+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>rabim birliğimizi ve beraberliğimizi daim etsi...</td>\n",
              "      <td>2019-04-12 05:30:00+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>bir ordunun muharebe vasıta ve usuleri alınabi...</td>\n",
              "      <td>2019-04-10 15:48:28+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2316 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... open\n",
              "0     pazar günü bulgaristan’da gerçekleşecek olan s...  ...    0\n",
              "1     gönlümüzde biriken tüm umutlarımızı yeşert ala...  ...    0\n",
              "2     ankara büyükşehir belediye başkanımız kıymetli...  ...    0\n",
              "3     türk miletinin fikrine kalbine ve ruhuna işlen...  ...    0\n",
              "4                            tbm grubu toplantımızdayız  ...    0\n",
              "...                                                 ...  ...  ...\n",
              "2495  sadece fransızların değil tüm insanlığın ortak...  ...    0\n",
              "2496  türk milî takımı formasını hem basketbol hem d...  ...    0\n",
              "2497  mesele tarih ise kanuni nin fransuva ya yazdığ...  ...    0\n",
              "2498  rabim birliğimizi ve beraberliğimizi daim etsi...  ...    0\n",
              "2499  bir ordunun muharebe vasıta ve usuleri alınabi...  ...    0\n",
              "\n",
              "[2316 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzOGrhVHmPkk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
